{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "# Read all the names (words)\n",
    "with open('names.txt') as f:\n",
    "    words = f.read().splitlines()\n",
    "print(len(words), words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 {'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "# Build the vocabulary of characters\n",
    "SPECIAL_CHAR = '.'\n",
    "vocab = [SPECIAL_CHAR] + sorted(list(set(''.join(words))))\n",
    "itoc = {i:c for i, c in enumerate(vocab)}\n",
    "ctoi = {c:i for i, c in itoc.items()}\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(VOCAB_SIZE, ctoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset\n",
    "X, y = [], []\n",
    "CONTEXT_DIM = 3\n",
    "\n",
    "for word in words:\n",
    "    context = [0] * CONTEXT_DIM\n",
    "    for char in word + SPECIAL_CHAR:\n",
    "        idx = ctoi[char]\n",
    "        X.append(context)\n",
    "        y.append(idx)\n",
    "        # print(''.join([itoc[i] for i in context]) + ' ---> ' + char)\n",
    "        context = context[1:] + [idx]\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, train_size=0.8)\n",
    "\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "valid_ds = TensorDataset(X_valid, y_valid)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=os.cpu_count() // 2, prefetch_factor=2)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, num_workers=os.cpu_count() // 2, prefetch_factor=2)\n",
    "test_dl = DataLoader(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 3\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, outputs: list) -> None:\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        outputs = [CONTEXT_DIM * EMB_DIM] +  outputs + [VOCAB_SIZE]\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(outputs) - 1):\n",
    "            self.layers.append(nn.Linear(outputs[i], outputs[i + 1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.flatten(x)\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            x = layer(x)\n",
    "            if i != len(self.layers):\n",
    "                x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import device_encoding\n",
    "from statistics import fmean\n",
    "\n",
    "def fit(model, epochs, loss_func, optimizer, train_dl, valid_dl):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    global_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        losses = [] \n",
    "        for step, data in enumerate(train_dl, 1):\n",
    "            X, y = data\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_func(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "            if step % 100 == 0:\n",
    "                # print(f'Epoch={epoch + 1} Step={step} Loss={fmean(losses):.3f}')\n",
    "                losses = []\n",
    "\n",
    "        model.eval()\n",
    "        valid_losses = []\n",
    "        for step, data in enumerate(valid_dl, 1):\n",
    "            X, y = data\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.no_grad():\n",
    "                loss = loss_func(model(X), y)\n",
    "            valid_losses.append(loss.item())\n",
    "        print(f'Epoch={epoch + 1} Validation Loss={fmean(valid_losses):.3f}')\n",
    "        global_losses.append(fmean(valid_losses))\n",
    "    # plt.plot(global_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP([16, 32])\n",
    "loss_func = F.cross_entropy\n",
    "optimizer = torch.optim.RMSprop(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1 Validation Loss=2.340\n",
      "Epoch=2 Validation Loss=2.318\n",
      "Epoch=3 Validation Loss=2.305\n",
      "Epoch=4 Validation Loss=2.296\n",
      "Epoch=5 Validation Loss=2.293\n",
      "Epoch=6 Validation Loss=2.293\n",
      "Epoch=7 Validation Loss=2.288\n",
      "Epoch=8 Validation Loss=2.287\n",
      "Epoch=9 Validation Loss=2.286\n",
      "Epoch=10 Validation Loss=2.285\n"
     ]
    }
   ],
   "source": [
    "fit(model, 10, loss_func, optimizer, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2950909489371028"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "results = []\n",
    "for X, y in test_dl:\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X)\n",
    "    probs = F.softmax(y_pred, dim=1)\n",
    "    _, preds = torch.max(probs.data, dim=1)    \n",
    "    results.append(preds.item() == y.item())\n",
    "mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hamari',\n",
       " 'joydrayzy',\n",
       " 'syany',\n",
       " 'mie',\n",
       " 'kakiir',\n",
       " 'aelisanyuchaymana',\n",
       " 'sety',\n",
       " 'jadojalee',\n",
       " 'jaanna',\n",
       " 'andi']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for i in range(10):\n",
    "    x = [0] * CONTEXT_DIM\n",
    "    output = ''\n",
    "    while True:\n",
    "        y_pred = model(torch.tensor([x]))\n",
    "        idx = torch.multinomial(y_pred.exp() / y_pred.exp().sum(), num_samples=1, replacement=True).item()\n",
    "        if idx == 0:\n",
    "            break\n",
    "        output += itoc[idx]\n",
    "        x = x[1:] + [idx]\n",
    "    preds.append(output)    \n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "766994926223b858c9015d8bbf5d6e334ae863186f5f93625656b074a8546d18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
